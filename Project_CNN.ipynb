{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ABZvQqVJCx"
      },
      "source": [
        "# ***IMAGE RECOGNITION USING CNN***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVn7dpQiVlz1"
      },
      "source": [
        "This project is basically implemented for image recognition by using cnn. CNN is nothing but the Convolution Neural Networks.Convolutional Neural Networks (CNN or ConvNet) is a subtype of Neural Networks that is mainly used for applications in image and speech recognition.In this project we will look into image recognition using CNN in CIFAR-10 Dataset. This CIFAR-10 dataset is imported from the datasets of keras.\n",
        "\n",
        "This dataset includes a matching label so we know what kind of image of it is.In this dataset the image consists of 3232 pxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDjig4-AU2EH"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten,Conv2D,MaxPooling2D\n",
        "from pathlib import Path\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_0ICnmZt5J"
      },
      "source": [
        "after importing the libraries loading of the dataset will be done and training and test\n",
        "x_tr=x train\n",
        "\n",
        "x_te=x test\n",
        "\n",
        "y_tr=y train\n",
        "\n",
        "y_te=y test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6AQ2lu3Zreq",
        "outputId": "10df335d-795e-4342-dc9a-b1b9f3611672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_tr,y_tr),(x_te,y_te)=cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cNbg9PWapRy"
      },
      "source": [
        "Normalization of dataset\n",
        "\n",
        "The data type is changed into the float datatype of 32 bit and then normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPjbZhb5aob6"
      },
      "outputs": [],
      "source": [
        "x_tr=x_tr.astype('float32')\n",
        "x_te=x_te.astype('float32')\n",
        "x_tr/=255.0\n",
        "x_te/=255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHxYaQTmb5TG"
      },
      "source": [
        "after normalization convert the class vectors to binary class matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUuS9DSUeEMJ"
      },
      "outputs": [],
      "source": [
        "y_tr=to_categorical(y_tr,10)\n",
        "y_te=to_categorical(y_te,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ5fxLT1fePg"
      },
      "source": [
        "Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
        "\n",
        "Kernel: In image processing kernel is a convolution matrix or masks which can be used for blurring, sharpening, embossing, edge detection, and more by doing a convolution between a kernel and an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvCv5mJyeM9I"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Bb11cxqwGH"
      },
      "source": [
        "Compilation of the Model this is done by using (model.compile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3u4mZj9oOAX",
        "outputId": "7b8693cd-4cd2-451a-da4f-74f77751bb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               590336    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642,570\n",
            "Trainable params: 642,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3xGg68hrgew"
      },
      "source": [
        "Fitting of data for the model.Here the data is fitted according to the size of batch. The training data of x,y are passed. Then validated data is passed by Test of x,y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y7CmZsHrkip",
        "outputId": "57bfd4ba-67bf-4a92-94ea-bc8a1a8bbdf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1563/1563 [==============================] - 243s 154ms/step - loss: 1.5755 - accuracy: 0.4213 - val_loss: 1.3111 - val_accuracy: 0.5367\n",
            "Epoch 2/8\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 1.2134 - accuracy: 0.5670 - val_loss: 1.0337 - val_accuracy: 0.6341\n",
            "Epoch 3/8\n",
            "1563/1563 [==============================] - 229s 146ms/step - loss: 1.0799 - accuracy: 0.6170 - val_loss: 0.9407 - val_accuracy: 0.6692\n",
            "Epoch 4/8\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 0.9893 - accuracy: 0.6497 - val_loss: 0.8599 - val_accuracy: 0.6978\n",
            "Epoch 5/8\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 0.9250 - accuracy: 0.6734 - val_loss: 0.8497 - val_accuracy: 0.7022\n",
            "Epoch 6/8\n",
            "1563/1563 [==============================] - 229s 147ms/step - loss: 0.8787 - accuracy: 0.6909 - val_loss: 0.8400 - val_accuracy: 0.7100\n",
            "Epoch 7/8\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 0.8434 - accuracy: 0.7024 - val_loss: 0.7626 - val_accuracy: 0.7379\n",
            "Epoch 8/8\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 0.8186 - accuracy: 0.7122 - val_loss: 0.7600 - val_accuracy: 0.7364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb2906c2e50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.fit(x_tr,y_tr,batch_size=32,epochs=8,validation_data=(x_te,y_te),shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JanOoIMZ39-Y"
      },
      "source": [
        "Saving the neural network architecture.here the data in transformed into json,then that is written by the model_structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3csCSvk5FfF",
        "outputId": "fd3aa5a5-2ac6-4a0b-ff0e-d2c8ec893caa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4384"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model_structure=model.to_json()\n",
        "f=Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7v6fa-55s6y"
      },
      "source": [
        "The saved format in json. we will also save the trained neural weights for predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rf7u_SB3oOv"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"model_weight.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYXw07H27eqY"
      },
      "source": [
        "Here the main part will come into the picture.The predictions will be made on the images based on the labels on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1QnIpVW7ePS"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKX3OhTP8CD8"
      },
      "source": [
        "class_labels are defined accordingly the division is made based on the labels of the class.\n",
        "\n",
        "for example, like horse,dog etc..,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2alWVdU7_9l"
      },
      "outputs": [],
      "source": [
        "class_labels=[\"Planes\",\"Car\",\"Bird\",\"Cat\",\"Deer\",\"Dog\",\"Frog\",\n",
        "              \"Horse\",\"Boat\",\"Truck\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSKSkkAc8quh"
      },
      "source": [
        "Loading of the json file that contains the model structure which we have loaded after fitting of the model is done.\n",
        "\n",
        "write_text for writing the data into the json file.\n",
        "\n",
        "read_text for reading the data from the json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inw8gl7O83te"
      },
      "outputs": [],
      "source": [
        "f=Path(\"model_structure.json\")\n",
        "model_Structure=f.read_text()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycNlJc0J9a5S"
      },
      "source": [
        "Loading of the image is done for testing. (load_img is used for loading the image) size is used as (32,32) as while creating the model the size given is (32,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Jh-ACKIt9RGw",
        "outputId": "2f8a02b9-2202-4d5f-eeb9-20f0ed369a08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb28ea41cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img,img_to_array\n",
        "img=load_img(\"/content/bird.jpeg\",target_size=(32,32))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIvHvR2z_Slr"
      },
      "source": [
        "After loading an image into a variable we have to convert the image to numpy array.here the image is converted to array and then expand according to dimensions of the array according to the row. (img_to_array is used for conversion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxZZnWZp-la0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "imgtest=img_to_array(img)\n",
        "list_of_image=np.expand_dims(imgtest,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxjQhDmdAUsH"
      },
      "source": [
        "After converting into the array.Then predictions are made on the basis of the array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTLHMOExATzV",
        "outputId": "21d391b7-66f0-4e6d-93a3-aaefb680d5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "res=model.predict(list_of_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujmvtsh0BXr1"
      },
      "source": [
        "only one result is taken into consideration as only one image is taken.if there are group of images then loop will be runned or the data set is classified accordingly.Printing of the array for all the labels will be done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Y9fcYdBWxx",
        "outputId": "a9caab5c-320c-4327-f2a3-e3e27aef7409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "sr=res[0]\n",
        "print(sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBh6ieC2BvEJ"
      },
      "source": [
        "we will get a score which represents for the likelihood of all 10 possible classes.when it gets the highest likelihood score then that label is given to that image. And the image label will be printed as a result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GHvCqObBuyu",
        "outputId": "fc7e1124-13ad-4574-9f2c-bd31f27b6a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bird 2\n"
          ]
        }
      ],
      "source": [
        "mostlci=int(np.argmax(sr))\n",
        "clh=class_labels[mostlci]\n",
        "print(clh,mostlci)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}